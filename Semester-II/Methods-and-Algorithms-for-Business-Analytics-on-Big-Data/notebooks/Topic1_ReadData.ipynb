{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Topic 1 – Reading Data\n",
    "\n",
    "In this notebook we focus on **reading and understanding data**.\n",
    "\n",
    "The goal is to:\n",
    "- load a real dataset from a CSV file\n",
    "- inspect its structure\n",
    "- understand observations, features, and missing values\n",
    "\n",
    "No modeling or prediction is performed here.\n"
   ],
   "id": "4f75b36cd8a77c55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What Does Reading Data Mean?\n",
    "\n",
    "Reading data means:\n",
    "- loading data from a file into Python\n",
    "- representing it in a structured form\n",
    "- understanding its rows, columns, and values\n",
    "\n",
    "In this course, data is usually read from **CSV files**\n",
    "and stored in **pandas DataFrames**.\n"
   ],
   "id": "d7ea808c9ee76d51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Required Libraries",
   "id": "da991a2629073418"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "63d6e2f5fba29006",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading a CSV File\n",
    "\n",
    "We now load a dataset from a CSV file.\n",
    "\n",
    "The dataset is stored in the `datasets/` folder.\n"
   ],
   "id": "9bf9e51336b00da4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../datasets/raw/Topic1/ILPD.csv\")\n",
    "df"
   ],
   "id": "dd6a2ee26df43b7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reading TXT Files\n",
    "\n",
    "Datasets are sometimes stored in TXT files instead of CSV files.\n",
    "\n",
    "TXT files usually contain tabular data where values are separated\n",
    "by a specific **delimiter**.\n",
    "\n",
    "Common delimiters:\n",
    "- comma (,)\n",
    "- semicolon (;)\n",
    "- tab (\\\\t)\n",
    "- pipe (|)\n"
   ],
   "id": "cbc762819717bc9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_txt = pd.read_csv(\n",
    "    \"../datasets/raw/Topic1/AutoInsurSweden.txt\",\n",
    "    sep=r\"\\s+\",      # split on whitespace (spaces or tabs)\n",
    "    decimal=\",\"      # comma is decimal separator\n",
    ")\n",
    "df_txt.head()\n",
    "\n",
    "# If the data does not load correctly, the delimiter may be wrong.\n",
    "# We can try different delimiters until the structure is correct."
   ],
   "id": "1e595b526157150b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Inspecting the First Rows\n",
    "\n",
    "To quickly understand a dataset, we usually look at its first few rows.\n"
   ],
   "id": "c4fa7d57818e8c7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.head()\n",
    "\n",
    "# This shows:\n",
    "# - column names\n",
    "# - example values\n",
    "# - general structure"
   ],
   "id": "67e99f00d85c57fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset Dimensions\n",
    "\n",
    "We now check:\n",
    "- how many observations (rows) the dataset has\n",
    "- how many features (columns) it contains"
   ],
   "id": "4502d1819bca9bb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Number of Rows and Columns\n",
    "\n",
    "df.shape\n",
    "\n",
    "# (number_of_rows, number_of_columns)"
   ],
   "id": "29cedf1ae04906b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Columns and Data Types\n",
    "\n",
    "Each column has:\n",
    "- a name\n",
    "- a data type (numeric, text, etc.)\n",
    "\n",
    "Understanding data types is essential before analysis.\n"
   ],
   "id": "835b6cc8c36a6db5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.info()\n",
    "\n",
    "# This shows\n",
    "# - columns names\n",
    "# - data types\n",
    "# - number of non-missing values"
   ],
   "id": "105464e12647d6f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Missing Values\n",
    "\n",
    "Real-world datasets often contain missing values.\n",
    "\n",
    "In pandas, missing values are represented as **NaN**.\n"
   ],
   "id": "9bff4ae71f01f29e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isna().sum()",
   "id": "897e9f1303e136ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dropping Rows with Missing Values\n",
    "\n",
    "One simple way to handle missing values is to **remove observations**\n",
    "that contain missing data.\n",
    "\n",
    "This means:\n",
    "- each row with at least one NaN value is removed\n",
    "- the dataset becomes smaller but cleaner\n",
    "\n",
    "Dropping rows is appropriate when:\n",
    "- the number of missing values is small\n",
    "- the dataset is large enough\n"
   ],
   "id": "97356a9e92fec2b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_clean = df.dropna()\n",
    "df_clean"
   ],
   "id": "a129f9b979c5febe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Effect of Dropping Rows\n",
    "\n",
    "We compare the size of the dataset before and after dropping missing values.\n"
   ],
   "id": "d5a2a8e91e738d14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T16:14:08.801184Z",
     "start_time": "2025-12-15T16:14:08.798578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Original dataset shape:\", df.shape)\n",
    "print(\"Cleaned dataset shape:\", df_clean.shape)"
   ],
   "id": "a826e240f82f5aaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (582, 11)\n",
      "Cleaned dataset shape: (578, 11)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Saving a DataFrame to a CSV File\n",
    "\n",
    "After cleaning or transforming a dataset, it is often useful to\n",
    "**save the result to a new CSV file**.\n",
    "\n",
    "This allows us to:\n",
    "- reuse cleaned data later\n",
    "- separate raw data from processed data\n",
    "- ensure reproducibility of the analysis"
   ],
   "id": "a13e6a1ed73f31f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_clean.to_csv( # writes the DataFrame to a CSV file\n",
    "    \"../datasets/processed/Topic1/ILPD_clean.csv\", # location of saved file\n",
    "    index=False # avoids saving the row index as a column\n",
    ")"
   ],
   "id": "2b1d8af688cceb83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why We Save Processed Data Separately\n",
    "\n",
    "- `datasets/raw/` contains original, unchanged data\n",
    "- `datasets/processed/` contains analytical decisions\n",
    "\n",
    "Saving processed data makes workflows:\n",
    "- reproducible\n",
    "- transparent\n",
    "- easier to continue in later topics\n"
   ],
   "id": "1cb74543a57e05b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Observations\n",
    "\n",
    "Reading TXT files follows the same logic as CSV files.\n",
    "The only difference is specifying the correct delimiter.\n",
    "\n",
    "Once loaded, TXT data is handled exactly like CSV data\n",
    "using pandas DataFrames.\n"
   ],
   "id": "123d1576746c0829"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Basic Statistical Overview\n",
    "\n",
    "Before any modeling, it is useful to look at basic statistics\n",
    "for numerical columns.\n"
   ],
   "id": "afbd82fb68ba41dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_clean.describe()\n",
    "\n",
    "# Includes:\n",
    "# - count\n",
    "# - mean\n",
    "# - standard deviation\n",
    "#  min/ max"
   ],
   "id": "5c231688a045a446",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Observations and Features\n",
    "\n",
    "- Each row represents one **observation**\n",
    "- Each column represents one **feature**\n",
    "\n",
    "Understanding this mapping is essential for regression\n",
    "and machine learning later.\n"
   ],
   "id": "113f0052c7222fdb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What Comes Next?\n",
    "\n",
    "Now that the data is loaded and understood, we are ready to:\n",
    "\n",
    "- select variables\n",
    "- split data into training and test sets\n",
    "- build regression models\n",
    "\n",
    "➡️ **Next: Topic 2 – Linear Regression**\n"
   ],
   "id": "a3a02ffdf17667ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
