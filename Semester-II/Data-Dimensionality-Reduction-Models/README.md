# Data Dimensionality Reduction Models (DDRM)

## ğŸ“˜ Course Overview
This repository contains theory notes, notebooks, and program-mode scripts for the master's-level course **"Data Dimensionality Reduction Models (DDRM)"**, part of the program *Modeling Big Data in Business and Finance* at Sofia University *St. Kliment Ohridski*.

The course focuses on:
- understanding **high-dimensional data** and the *curse of dimensionality*
- reducing dimensions for **visualization, compression, denoising, and modeling**
- applying classic and modern **dimensionality reduction techniques**
- evaluating trade-offs between **information retention, interpretability, and performance**

The repository is designed to be:
- âœ… exam-oriented  
- âœ… learning-oriented  
- âœ… reusable as a professional portfolio  

---

## ğŸ¯ Learning Objectives
By working through this repository, the goal is to:
- Understand *why* dimensionality reduction is needed in business analytics
- Distinguish **feature selection** vs **feature extraction**
- Apply linear methods (e.g., PCA/SVD) and nonlinear methods (e.g., manifold learning)
- Use DR for:
  - visualization and exploratory analysis
  - preprocessing before clustering/classification/regression
  - noise reduction and compression
- Evaluate DR methods using:
  - explained variance / reconstruction error
  - neighborhood preservation (for manifold methods)
  - downstream model performance (task-based evaluation)
- Communicate results clearly: *what was reduced, what was preserved, and what was lost*

---

## ğŸ§  Course Context & Methodology
Dimensionality reduction is not just â€œmaking data smallerâ€ â€” itâ€™s about finding **useful structure** in high-dimensional spaces.

The course is approached as a practical pipeline:
1. Understand the **data geometry** (scales, correlations, sparsity)
2. Choose a DR objective:
   - preserve variance (PCA-style)
   - preserve distances (MDS-style)
   - preserve neighborhoods (t-SNE/UMAP-style)
   - preserve information relevant to a target (supervised DR / feature selection)
3. Apply the method correctly (scaling, hyperparameters, diagnostics)
4. Evaluate both:
   - **mathematical quality** (reconstruction / structure)
   - **business usefulness** (interpretability / predictive value)
5. Document results in a reusable, lecture-by-lecture format

---

## ğŸ› ï¸ Tools & Environment
The repository uses a reproducible Python environment.

Typical libraries used:
- numpy
- pandas
- scipy
- matplotlib
- scikit-learn

Optional (when needed):
- umap-learn (UMAP)
- tensorflow / keras or pytorch (autoencoders / deep DR)

---

## ğŸ“‚ Repository Structure
```text
Data-Dimensionality-Reduction-Models/
â”‚
â”œâ”€â”€ datasets/ # Raw and processed datasets + documentation
â”‚ â”œâ”€â”€ raw/
â”‚ â”œâ”€â”€ processed/
â”‚ â””â”€â”€ README.md
â”‚
â”œâ”€â”€ notebooks/ # Jupyter notebooks for exploration & intuition
â”‚
â”œâ”€â”€ resources/ # Official lecture slides, PDFs, homework descriptions
â”‚
â”œâ”€â”€ scripts/ # Python scripts (program mode)
â”‚ â”œâ”€â”€ exercises/ # Practice scripts
â”‚ â”œâ”€â”€ homework/ # Assignment scripts
â”‚ â””â”€â”€ README.md
â”‚
â”œâ”€â”€ theory/ # Markdown notes with structured explanations
â”‚ â”œâ”€â”€ _cheatsheet.md
â”‚ â”œâ”€â”€ _glossary.md
â”‚ â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md # This file
