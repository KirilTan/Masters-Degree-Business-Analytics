{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6292baef",
   "metadata": {},
   "source": [
    "# Topic 2 B Logistic Regression vs LDA (Pipeline)\n",
    "\n",
    "**Corresponding script:**\n",
    "- `scripts/exercises/log_reg_lda_ex1.py`\n",
    "\n",
    "## Learning goals\n",
    "- Understand LDA used as a **supervised transformer** inside a pipeline\n",
    "- Compare **baseline Logistic Regression** vs **LDA → Logistic Regression**\n",
    "- Reinforce the key rule: for binary classification, LDA has max **1** component\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4613d11f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T16:29:19.937906400Z",
     "start_time": "2025-12-28T16:29:19.917199Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "cb4212b6",
   "metadata": {},
   "source": [
    "## 1) Dataset with redundancy (multicollinearity-like)\n",
    "\n",
    "We generate a dataset with:\n",
    "- many features (20)\n",
    "- 10 informative\n",
    "- 10 redundant (correlated combinations of informative ones)\n",
    "\n",
    "This is exactly the situation where dimensionality reduction can help:\n",
    "- remove redundancy\n",
    "- simplify the model’s input space\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "84ea23ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T16:29:19.988612200Z",
     "start_time": "2025-12-28T16:29:19.951417200Z"
    }
   },
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=10,\n",
    "    random_state=7\n",
    ")\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Class counts:\", np.bincount(y))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000, 20)\n",
      "Class counts: [505 495]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "a57c5a25",
   "metadata": {},
   "source": [
    "## 2) Evaluation setup (Repeated Stratified K-Fold)\n",
    "\n",
    "We use the same CV approach as in Topic 1:\n",
    "- stratified folds\n",
    "- repeated multiple times\n",
    "\n",
    "This gives a stable estimate of mean accuracy and its variability.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "03ca8bb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T16:29:19.996690Z",
     "start_time": "2025-12-28T16:29:19.990611Z"
    }
   },
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "0f725989",
   "metadata": {},
   "source": [
    "## 3) Baseline: Logistic Regression on raw features\n",
    "\n",
    "Logistic Regression is a linear classifier.\n",
    "\n",
    "It computes a score:\n",
    "\n",
    "$$\n",
    "\\hat{y} = w^T x + b\n",
    "$$\n",
    "\n",
    "Then converts it to a probability via the sigmoid function (binary case), and predicts a class.\n",
    "\n",
    "This baseline answers:\n",
    "> How well can a simple linear model work **without** dimensionality reduction?\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4865869c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T16:29:20.065707500Z",
     "start_time": "2025-12-28T16:29:19.997690300Z"
    }
   },
   "source": [
    "baseline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "scores_base = cross_val_score(baseline, X, y, scoring=\"accuracy\", cv=cv, n_jobs=-1)\n",
    "\n",
    "print(f\"Baseline LogReg accuracy: {scores_base.mean():.3f} ± {scores_base.std():.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline LogReg accuracy: 0.825 ± 0.034\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "52fb1ee8",
   "metadata": {},
   "source": [
    "## 4) LDA → Logistic Regression pipeline\n",
    "\n",
    "Now we insert LDA **before** Logistic Regression.\n",
    "\n",
    "Important constraint:\n",
    "\n",
    "$$\n",
    "n\\_{components} \\le C - 1\n",
    "$$\n",
    "\n",
    "Here we have **C = 2 classes**, so `n_components` can only be **1**.\n",
    "\n",
    "So we build:\n",
    "\n",
    "`StandardScaler → LDA(1) → LogisticRegression`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "40c6c63b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T16:29:20.115083200Z",
     "start_time": "2025-12-28T16:29:20.067710Z"
    }
   },
   "source": [
    "lda_logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lda\", LinearDiscriminantAnalysis(n_components=1)),\n",
    "    (\"logreg\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "scores_lda = cross_val_score(lda_logreg, X, y, scoring=\"accuracy\", cv=cv, n_jobs=-1)\n",
    "\n",
    "print(f\"LDA(1)+LogReg accuracy: {scores_lda.mean():.3f} ± {scores_lda.std():.3f}\")\n",
    "print(f\"Delta (LDA - baseline): {(scores_lda.mean() - scores_base.mean()):.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA(1)+LogReg accuracy: 0.825 ± 0.034\n",
      "Delta (LDA - baseline): 0.0000\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "eaa5e324",
   "metadata": {},
   "source": [
    "## ✅ Interpretation of results (Topic 2B)\n",
    "\n",
    "We compared two cross-validated pipelines:\n",
    "\n",
    "- **Baseline:** StandardScaler → Logistic Regression\n",
    "- **LDA pipeline:** StandardScaler → LDA(1) → Logistic Regression\n",
    "\n",
    "Results:\n",
    "\n",
    "- Baseline accuracy: **0.825 ± 0.034**\n",
    "- LDA(1)+LogReg accuracy: **0.825 ± 0.034**\n",
    "- Δ (LDA − baseline): **0.0000**\n",
    "\n",
    "### What this means\n",
    "- LDA did **not** change performance on this dataset.\n",
    "- This is common when the problem is already well-solved by a linear classifier (LogReg).\n",
    "- In binary classification, LDA can produce only **one** discriminant axis:\n",
    "\n",
    "$$\n",
    "n_{\\text{components}} \\le C-1 = 1\n",
    "$$\n",
    "\n",
    "So LDA compresses the data into **LD1**. If LD1 preserves nearly all class-separating information, accuracy stays the same.\n",
    "\n",
    "### Takeaway\n",
    "- LDA is **not guaranteed** to improve accuracy.\n",
    "- Its benefit here is mainly **supervised dimensionality reduction** (simpler representation), not better prediction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "name": "conda-base-py",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
